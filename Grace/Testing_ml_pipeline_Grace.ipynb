{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "\n",
    "#Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "sys.path.insert(0, '/Users/gracewang/Documents/GitHub/elecfinal')\n",
    "sys.path.insert(0, 'D:\\Fall23 Coursework\\ELEC478\\Competition\\elecfinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_pipeline import train_n_predict, validation, clean_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.data_cleaner import cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean data\n",
    "train_path = \"../Data/train_data.csv\"\n",
    "feature_path = \"../Data/feature_weights.csv\"\n",
    "morph_path = \"../Data/imputed_morph_embed.csv\"\n",
    "X_train, X_val, X_query, y_train, y_val, y_query = clean_split(train_path, feature_path, morph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'adp_dist', 'post_skeletal_distance_to_soma',\n",
       "       'pre_skeletal_distance_to_soma', 'pre_oracle', 'pre_test_score',\n",
       "       'post_oracle', 'post_test_score', 'compartment', 'pre_brain_area',\n",
       "       'post_brain_area', 'post_nucleus_x', 'post_nucleus_y', 'post_nucleus_z',\n",
       "       'pre_nucleus_id', 'post_nucleus_id', 'pre_feature_weights',\n",
       "       'post_feature_weights', 'pre_morph_embeddings', 'post_morph_embeddings',\n",
       "       'me_similarity', 'fw_similarity', 'projection_group', 'axonal_coords',\n",
       "       'dendritic_coords', 'pre_rf_coords', 'post_rf_coords',\n",
       "       'pre_nucleus_coords', 'nuclei_adp_dist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Feature Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights = pd.read_csv(feature_path)\n",
    "X_train_fw = feature_weights.merge(X_train['pre_nucleus_id'], right_on ='pre_nucleus_id', left_on='nucleus_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "feature_counts = defaultdict(int)\n",
    "for rep in range(50):\n",
    "    model = RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "    model.fit(X_train_fw.drop(columns=['pre_nucleus_id', 'nucleus_id']), y_train)\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    imp_df = pd.DataFrame({\"Features\":X_train_fw.drop(columns=['pre_nucleus_id', 'nucleus_id']).columns, \"Importance\":importances})\n",
    "\n",
    "    imp_df = imp_df.sort_values('Importance', ascending=False)\n",
    "    for feature in imp_df['Features'][0:5]:\n",
    "        feature_counts[feature]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nucleus_id</th>\n",
       "      <th>feature_weight_330</th>\n",
       "      <th>feature_weight_328</th>\n",
       "      <th>ID</th>\n",
       "      <th>adp_dist</th>\n",
       "      <th>post_skeletal_distance_to_soma</th>\n",
       "      <th>pre_skeletal_distance_to_soma</th>\n",
       "      <th>pre_oracle</th>\n",
       "      <th>pre_test_score</th>\n",
       "      <th>post_oracle</th>\n",
       "      <th>...</th>\n",
       "      <th>post_morph_embeddings</th>\n",
       "      <th>me_similarity</th>\n",
       "      <th>fw_similarity</th>\n",
       "      <th>projection_group</th>\n",
       "      <th>axonal_coords</th>\n",
       "      <th>dendritic_coords</th>\n",
       "      <th>pre_rf_coords</th>\n",
       "      <th>post_rf_coords</th>\n",
       "      <th>pre_nucleus_coords</th>\n",
       "      <th>nuclei_adp_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582129</td>\n",
       "      <td>-0.206426</td>\n",
       "      <td>0.211415</td>\n",
       "      <td>48656</td>\n",
       "      <td>-1.383514</td>\n",
       "      <td>1.328283</td>\n",
       "      <td>-0.607981</td>\n",
       "      <td>-1.553935</td>\n",
       "      <td>-0.362281</td>\n",
       "      <td>1.191761</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.0723994970321655, -0.7540942430496216, 0.11...</td>\n",
       "      <td>1.077231</td>\n",
       "      <td>-1.065146</td>\n",
       "      <td>AL-&gt;RL</td>\n",
       "      <td>[1265270, 450597, 920661]</td>\n",
       "      <td>[1265640, 450398, 920262]</td>\n",
       "      <td>[855.0040316581726, 544.8585534095764]</td>\n",
       "      <td>[858.5207009315491, 608.4342455863953]</td>\n",
       "      <td>[1311616, 473664, 757880]</td>\n",
       "      <td>-0.348809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>582129</td>\n",
       "      <td>-0.206426</td>\n",
       "      <td>0.211415</td>\n",
       "      <td>48657</td>\n",
       "      <td>-1.355662</td>\n",
       "      <td>1.538367</td>\n",
       "      <td>-0.673488</td>\n",
       "      <td>-1.553935</td>\n",
       "      <td>-0.362281</td>\n",
       "      <td>1.191761</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.0723994970321655, -0.7540942430496216, 0.11...</td>\n",
       "      <td>1.077231</td>\n",
       "      <td>-1.065146</td>\n",
       "      <td>AL-&gt;RL</td>\n",
       "      <td>[1230790, 692832, 844011]</td>\n",
       "      <td>[1231270, 692894, 844399]</td>\n",
       "      <td>[855.0040316581726, 544.8585534095764]</td>\n",
       "      <td>[858.5207009315491, 608.4342455863953]</td>\n",
       "      <td>[1311616, 473664, 757880]</td>\n",
       "      <td>0.128893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>582129</td>\n",
       "      <td>-0.206426</td>\n",
       "      <td>0.211415</td>\n",
       "      <td>48658</td>\n",
       "      <td>0.476569</td>\n",
       "      <td>2.996159</td>\n",
       "      <td>-0.845149</td>\n",
       "      <td>-1.553935</td>\n",
       "      <td>-0.362281</td>\n",
       "      <td>1.191761</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.0723994970321655, -0.7540942430496216, 0.11...</td>\n",
       "      <td>1.077231</td>\n",
       "      <td>-1.065146</td>\n",
       "      <td>AL-&gt;RL</td>\n",
       "      <td>[1300030, 524790, 861672]</td>\n",
       "      <td>[1301040, 521794, 860782]</td>\n",
       "      <td>[855.0040316581726, 544.8585534095764]</td>\n",
       "      <td>[858.5207009315491, 608.4342455863953]</td>\n",
       "      <td>[1311616, 473664, 757880]</td>\n",
       "      <td>-0.682142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>582129</td>\n",
       "      <td>-0.206426</td>\n",
       "      <td>0.211415</td>\n",
       "      <td>48659</td>\n",
       "      <td>0.896940</td>\n",
       "      <td>-0.705250</td>\n",
       "      <td>-0.631973</td>\n",
       "      <td>-1.553935</td>\n",
       "      <td>-0.362281</td>\n",
       "      <td>1.191761</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.0723994970321655, -0.7540942430496216, 0.11...</td>\n",
       "      <td>1.077231</td>\n",
       "      <td>-1.065146</td>\n",
       "      <td>AL-&gt;RL</td>\n",
       "      <td>[1190930, 458724, 919590]</td>\n",
       "      <td>[1192510, 455252, 918028]</td>\n",
       "      <td>[855.0040316581726, 544.8585534095764]</td>\n",
       "      <td>[858.5207009315491, 608.4342455863953]</td>\n",
       "      <td>[1311616, 473664, 757880]</td>\n",
       "      <td>-0.156166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>582129</td>\n",
       "      <td>-0.206426</td>\n",
       "      <td>0.211415</td>\n",
       "      <td>48660</td>\n",
       "      <td>1.110236</td>\n",
       "      <td>2.716134</td>\n",
       "      <td>-0.858720</td>\n",
       "      <td>-1.553935</td>\n",
       "      <td>-0.362281</td>\n",
       "      <td>1.191761</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.0723994970321655, -0.7540942430496216, 0.11...</td>\n",
       "      <td>1.077231</td>\n",
       "      <td>-1.065146</td>\n",
       "      <td>AL-&gt;RL</td>\n",
       "      <td>[1280940, 662046, 800268]</td>\n",
       "      <td>[1282930, 660720, 803718]</td>\n",
       "      <td>[855.0040316581726, 544.8585534095764]</td>\n",
       "      <td>[858.5207009315491, 608.4342455863953]</td>\n",
       "      <td>[1311616, 473664, 757880]</td>\n",
       "      <td>-0.197845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118898</th>\n",
       "      <td>294858</td>\n",
       "      <td>-0.383717</td>\n",
       "      <td>-0.206139</td>\n",
       "      <td>224656</td>\n",
       "      <td>-1.153476</td>\n",
       "      <td>0.399766</td>\n",
       "      <td>-0.718692</td>\n",
       "      <td>0.577790</td>\n",
       "      <td>-0.460852</td>\n",
       "      <td>-0.024162</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.4674314260482788, 0.6272068619728088, 0.410...</td>\n",
       "      <td>0.278531</td>\n",
       "      <td>-0.033703</td>\n",
       "      <td>V1-&gt;V1</td>\n",
       "      <td>[815199, 840966, 936012]</td>\n",
       "      <td>[815423, 841222, 936912]</td>\n",
       "      <td>[831.2186741828918, 560.7675075531006]</td>\n",
       "      <td>[894.7975826263428, 590.8018326759338]</td>\n",
       "      <td>[770240, 531136, 920360]</td>\n",
       "      <td>0.523107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118899</th>\n",
       "      <td>294858</td>\n",
       "      <td>-0.383717</td>\n",
       "      <td>-0.206139</td>\n",
       "      <td>224657</td>\n",
       "      <td>-0.241583</td>\n",
       "      <td>-0.349050</td>\n",
       "      <td>-1.047622</td>\n",
       "      <td>0.577790</td>\n",
       "      <td>-0.460852</td>\n",
       "      <td>-0.024162</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.4674314260482788, 0.6272068619728088, 0.410...</td>\n",
       "      <td>0.278531</td>\n",
       "      <td>-0.033703</td>\n",
       "      <td>V1-&gt;V1</td>\n",
       "      <td>[781179, 711648, 913773]</td>\n",
       "      <td>[781156, 713918, 914591]</td>\n",
       "      <td>[831.2186741828918, 560.7675075531006]</td>\n",
       "      <td>[894.7975826263428, 590.8018326759338]</td>\n",
       "      <td>[770240, 531136, 920360]</td>\n",
       "      <td>-0.286781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118900</th>\n",
       "      <td>294858</td>\n",
       "      <td>-0.383717</td>\n",
       "      <td>-0.206139</td>\n",
       "      <td>224658</td>\n",
       "      <td>0.554607</td>\n",
       "      <td>-0.541337</td>\n",
       "      <td>-0.882155</td>\n",
       "      <td>0.577790</td>\n",
       "      <td>-0.460852</td>\n",
       "      <td>-0.024162</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.4674314260482788, 0.6272068619728088, 0.410...</td>\n",
       "      <td>0.278531</td>\n",
       "      <td>-0.033703</td>\n",
       "      <td>V1-&gt;V1</td>\n",
       "      <td>[792729, 700644, 853209]</td>\n",
       "      <td>[796175, 699876, 854748]</td>\n",
       "      <td>[831.2186741828918, 560.7675075531006]</td>\n",
       "      <td>[894.7975826263428, 590.8018326759338]</td>\n",
       "      <td>[770240, 531136, 920360]</td>\n",
       "      <td>-0.270014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118901</th>\n",
       "      <td>294858</td>\n",
       "      <td>-0.383717</td>\n",
       "      <td>-0.206139</td>\n",
       "      <td>224659</td>\n",
       "      <td>1.086661</td>\n",
       "      <td>-0.653431</td>\n",
       "      <td>-0.854285</td>\n",
       "      <td>0.577790</td>\n",
       "      <td>-0.460852</td>\n",
       "      <td>-0.024162</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.4674314260482788, 0.6272068619728088, 0.410...</td>\n",
       "      <td>0.278531</td>\n",
       "      <td>-0.033703</td>\n",
       "      <td>V1-&gt;V1</td>\n",
       "      <td>[790671, 741048, 834960]</td>\n",
       "      <td>[789421, 744192, 837710]</td>\n",
       "      <td>[831.2186741828918, 560.7675075531006]</td>\n",
       "      <td>[894.7975826263428, 590.8018326759338]</td>\n",
       "      <td>[770240, 531136, 920360]</td>\n",
       "      <td>-0.002103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118902</th>\n",
       "      <td>294858</td>\n",
       "      <td>-0.383717</td>\n",
       "      <td>-0.206139</td>\n",
       "      <td>224660</td>\n",
       "      <td>1.087260</td>\n",
       "      <td>-0.656717</td>\n",
       "      <td>-0.918550</td>\n",
       "      <td>0.577790</td>\n",
       "      <td>-0.460852</td>\n",
       "      <td>-0.024162</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.4674314260482788, 0.6272068619728088, 0.410...</td>\n",
       "      <td>0.278531</td>\n",
       "      <td>-0.033703</td>\n",
       "      <td>V1-&gt;V1</td>\n",
       "      <td>[798126, 711774, 859950]</td>\n",
       "      <td>[802176, 710250, 858198]</td>\n",
       "      <td>[831.2186741828918, 560.7675075531006]</td>\n",
       "      <td>[894.7975826263428, 590.8018326759338]</td>\n",
       "      <td>[770240, 531136, 920360]</td>\n",
       "      <td>-0.216251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118903 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        nucleus_id  feature_weight_330  feature_weight_328      ID  adp_dist  \\\n",
       "0           582129           -0.206426            0.211415   48656 -1.383514   \n",
       "1           582129           -0.206426            0.211415   48657 -1.355662   \n",
       "2           582129           -0.206426            0.211415   48658  0.476569   \n",
       "3           582129           -0.206426            0.211415   48659  0.896940   \n",
       "4           582129           -0.206426            0.211415   48660  1.110236   \n",
       "...            ...                 ...                 ...     ...       ...   \n",
       "118898      294858           -0.383717           -0.206139  224656 -1.153476   \n",
       "118899      294858           -0.383717           -0.206139  224657 -0.241583   \n",
       "118900      294858           -0.383717           -0.206139  224658  0.554607   \n",
       "118901      294858           -0.383717           -0.206139  224659  1.086661   \n",
       "118902      294858           -0.383717           -0.206139  224660  1.087260   \n",
       "\n",
       "        post_skeletal_distance_to_soma  pre_skeletal_distance_to_soma  \\\n",
       "0                             1.328283                      -0.607981   \n",
       "1                             1.538367                      -0.673488   \n",
       "2                             2.996159                      -0.845149   \n",
       "3                            -0.705250                      -0.631973   \n",
       "4                             2.716134                      -0.858720   \n",
       "...                                ...                            ...   \n",
       "118898                        0.399766                      -0.718692   \n",
       "118899                       -0.349050                      -1.047622   \n",
       "118900                       -0.541337                      -0.882155   \n",
       "118901                       -0.653431                      -0.854285   \n",
       "118902                       -0.656717                      -0.918550   \n",
       "\n",
       "        pre_oracle  pre_test_score  post_oracle  ...  \\\n",
       "0        -1.553935       -0.362281     1.191761  ...   \n",
       "1        -1.553935       -0.362281     1.191761  ...   \n",
       "2        -1.553935       -0.362281     1.191761  ...   \n",
       "3        -1.553935       -0.362281     1.191761  ...   \n",
       "4        -1.553935       -0.362281     1.191761  ...   \n",
       "...            ...             ...          ...  ...   \n",
       "118898    0.577790       -0.460852    -0.024162  ...   \n",
       "118899    0.577790       -0.460852    -0.024162  ...   \n",
       "118900    0.577790       -0.460852    -0.024162  ...   \n",
       "118901    0.577790       -0.460852    -0.024162  ...   \n",
       "118902    0.577790       -0.460852    -0.024162  ...   \n",
       "\n",
       "                                    post_morph_embeddings me_similarity  \\\n",
       "0       [1.0723994970321655, -0.7540942430496216, 0.11...      1.077231   \n",
       "1       [1.0723994970321655, -0.7540942430496216, 0.11...      1.077231   \n",
       "2       [1.0723994970321655, -0.7540942430496216, 0.11...      1.077231   \n",
       "3       [1.0723994970321655, -0.7540942430496216, 0.11...      1.077231   \n",
       "4       [1.0723994970321655, -0.7540942430496216, 0.11...      1.077231   \n",
       "...                                                   ...           ...   \n",
       "118898  [1.4674314260482788, 0.6272068619728088, 0.410...      0.278531   \n",
       "118899  [1.4674314260482788, 0.6272068619728088, 0.410...      0.278531   \n",
       "118900  [1.4674314260482788, 0.6272068619728088, 0.410...      0.278531   \n",
       "118901  [1.4674314260482788, 0.6272068619728088, 0.410...      0.278531   \n",
       "118902  [1.4674314260482788, 0.6272068619728088, 0.410...      0.278531   \n",
       "\n",
       "       fw_similarity projection_group              axonal_coords  \\\n",
       "0          -1.065146           AL->RL  [1265270, 450597, 920661]   \n",
       "1          -1.065146           AL->RL  [1230790, 692832, 844011]   \n",
       "2          -1.065146           AL->RL  [1300030, 524790, 861672]   \n",
       "3          -1.065146           AL->RL  [1190930, 458724, 919590]   \n",
       "4          -1.065146           AL->RL  [1280940, 662046, 800268]   \n",
       "...              ...              ...                        ...   \n",
       "118898     -0.033703           V1->V1   [815199, 840966, 936012]   \n",
       "118899     -0.033703           V1->V1   [781179, 711648, 913773]   \n",
       "118900     -0.033703           V1->V1   [792729, 700644, 853209]   \n",
       "118901     -0.033703           V1->V1   [790671, 741048, 834960]   \n",
       "118902     -0.033703           V1->V1   [798126, 711774, 859950]   \n",
       "\n",
       "                 dendritic_coords                           pre_rf_coords  \\\n",
       "0       [1265640, 450398, 920262]  [855.0040316581726, 544.8585534095764]   \n",
       "1       [1231270, 692894, 844399]  [855.0040316581726, 544.8585534095764]   \n",
       "2       [1301040, 521794, 860782]  [855.0040316581726, 544.8585534095764]   \n",
       "3       [1192510, 455252, 918028]  [855.0040316581726, 544.8585534095764]   \n",
       "4       [1282930, 660720, 803718]  [855.0040316581726, 544.8585534095764]   \n",
       "...                           ...                                     ...   \n",
       "118898   [815423, 841222, 936912]  [831.2186741828918, 560.7675075531006]   \n",
       "118899   [781156, 713918, 914591]  [831.2186741828918, 560.7675075531006]   \n",
       "118900   [796175, 699876, 854748]  [831.2186741828918, 560.7675075531006]   \n",
       "118901   [789421, 744192, 837710]  [831.2186741828918, 560.7675075531006]   \n",
       "118902   [802176, 710250, 858198]  [831.2186741828918, 560.7675075531006]   \n",
       "\n",
       "                                post_rf_coords         pre_nucleus_coords  \\\n",
       "0       [858.5207009315491, 608.4342455863953]  [1311616, 473664, 757880]   \n",
       "1       [858.5207009315491, 608.4342455863953]  [1311616, 473664, 757880]   \n",
       "2       [858.5207009315491, 608.4342455863953]  [1311616, 473664, 757880]   \n",
       "3       [858.5207009315491, 608.4342455863953]  [1311616, 473664, 757880]   \n",
       "4       [858.5207009315491, 608.4342455863953]  [1311616, 473664, 757880]   \n",
       "...                                        ...                        ...   \n",
       "118898  [894.7975826263428, 590.8018326759338]   [770240, 531136, 920360]   \n",
       "118899  [894.7975826263428, 590.8018326759338]   [770240, 531136, 920360]   \n",
       "118900  [894.7975826263428, 590.8018326759338]   [770240, 531136, 920360]   \n",
       "118901  [894.7975826263428, 590.8018326759338]   [770240, 531136, 920360]   \n",
       "118902  [894.7975826263428, 590.8018326759338]   [770240, 531136, 920360]   \n",
       "\n",
       "       nuclei_adp_dist  \n",
       "0            -0.348809  \n",
       "1             0.128893  \n",
       "2            -0.682142  \n",
       "3            -0.156166  \n",
       "4            -0.197845  \n",
       "...                ...  \n",
       "118898        0.523107  \n",
       "118899       -0.286781  \n",
       "118900       -0.270014  \n",
       "118901       -0.002103  \n",
       "118902       -0.216251  \n",
       "\n",
       "[118903 rows x 32 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_fw = feature_weights[[\"nucleus_id\", \"feature_weight_330\", 'feature_weight_328']]\n",
    "X_train = keep_fw.merge(X_train, left_on='nucleus_id', right_on='pre_nucleus_id')\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/categorical.py:1794: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/categorical.py:1794: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x312126c90>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final = X_train\n",
    "final['connected']=y_train\n",
    "sns.catplot(x='connected', y='feature_weight_328', data=final, kind='boxen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding of Compartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['axon', 'apical_tuft', 'basal', 'apical', 'oblique',\n",
       "       'apical_shaft', 'soma'], dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different compartments\n",
    "pd.unique(X_train[\"compartment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "area1 = [\"basal\", \"soma\"]\n",
    "area2 = [\"axon\", \"apical\", \"oblique\", \"apical_shaft\"]\n",
    "area3 = [\"apical_tuft\"]\n",
    "\n",
    "def area_cols(df):\n",
    "    df[\"area1\"] = df[\"compartment\"].isin(area1).astype('int')\n",
    "    df[\"area2\"] = df[\"compartment\"].isin(area2).astype('int')\n",
    "    df[\"area3\"] = df[\"compartment\"].isin(area3).astype('int')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = area_cols(X_train)\n",
    "X_val = area_cols(X_val)\n",
    "X_query = area_cols(X_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         AL\n",
       "1         AL\n",
       "2         AL\n",
       "3         AL\n",
       "4         AL\n",
       "          ..\n",
       "118898    V1\n",
       "118899    V1\n",
       "118900    V1\n",
       "118901    V1\n",
       "118902    V1\n",
       "Name: pre_brain_area, Length: 118903, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['pre_brain_area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding of all Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(column, df, suffix=''):\n",
    "    \"\"\"\n",
    "    one-hot encodes this shit\n",
    "    \"\"\"\n",
    "    cats = pd.unique(df[column])\n",
    "\n",
    "    for cat in cats:\n",
    "        new_col = cat+suffix\n",
    "        df[new_col] = df[column]==cat\n",
    "        df[new_col] = df[new_col].astype('int')\n",
    "    \n",
    "    df = df.drop(columns=column)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1hot = one_hot('pre_brain_area', X_train, '_pre')\n",
    "X_train_1hot = one_hot('post_brain_area', X_train_1hot, '_post')\n",
    "X_train_1hot = one_hot('projection_group', X_train_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1hot = X_train_1hot.drop(columns='compartment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nucleus_id                          int64\n",
       "feature_weight_330                float64\n",
       "feature_weight_328                float64\n",
       "ID                                  int64\n",
       "adp_dist                          float64\n",
       "post_skeletal_distance_to_soma    float64\n",
       "pre_skeletal_distance_to_soma     float64\n",
       "pre_oracle                        float64\n",
       "pre_test_score                    float64\n",
       "post_oracle                       float64\n",
       "post_test_score                   float64\n",
       "post_nucleus_x                    float64\n",
       "post_nucleus_y                    float64\n",
       "post_nucleus_z                    float64\n",
       "pre_nucleus_id                      int64\n",
       "post_nucleus_id                     int64\n",
       "pre_feature_weights                object\n",
       "post_feature_weights               object\n",
       "pre_morph_embeddings               object\n",
       "post_morph_embeddings              object\n",
       "me_similarity                     float64\n",
       "fw_similarity                     float64\n",
       "axonal_coords                      object\n",
       "dendritic_coords                   object\n",
       "pre_rf_coords                      object\n",
       "post_rf_coords                     object\n",
       "pre_nucleus_coords                 object\n",
       "nuclei_adp_dist                   float64\n",
       "area1                               int64\n",
       "area2                               int64\n",
       "area3                               int64\n",
       "AL_pre                              int64\n",
       "RL_pre                              int64\n",
       "V1_pre                              int64\n",
       "RL_post                             int64\n",
       "V1_post                             int64\n",
       "AL_post                             int64\n",
       "AL->RL                              int64\n",
       "AL->V1                              int64\n",
       "AL->AL                              int64\n",
       "RL->RL                              int64\n",
       "RL->V1                              int64\n",
       "RL->AL                              int64\n",
       "V1->V1                              int64\n",
       "V1->RL                              int64\n",
       "V1->AL                              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1hot.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "feature_counts = defaultdict(int)\n",
    "for rep in range(50):\n",
    "    model = RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "    model.fit(X_train_1hot.select_dtypes('number').drop(columns=['ID', 'nucleus_id']), y_train)\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    imp_df = pd.DataFrame({\"Features\":X_train_1hot.select_dtypes('number').drop(columns=['ID', 'nucleus_id']).columns, \"Importance\":importances})\n",
    "\n",
    "    imp_df = imp_df.sort_values('Importance', ascending=False)\n",
    "    for feature in imp_df['Features'][0:5]:\n",
    "        feature_counts[feature]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'adp_dist': 50,\n",
       "             'pre_skeletal_distance_to_soma': 50,\n",
       "             'nuclei_adp_dist': 50,\n",
       "             'post_skeletal_distance_to_soma': 50,\n",
       "             'fw_similarity': 46,\n",
       "             'me_similarity': 4})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "Create clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X_train['post_nucleus_x'], y=X_train['post_nucleus_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = SpectralClustering(n_clusters= 4, assign_labels='kmeans', affinity = 'nearest_neighbors').fit(X_train[[\"post_nucleus_x\", \"post_nucleus_y\"]])\n",
    "X_train[\"cluster\"] = clustering.fit_predict(X_train[[\"post_nucleus_x\", \"post_nucleus_y\"]])\n",
    "sns.scatterplot(data=X_train, x=\"post_nucleus_x\", y=\"post_nucleus_y\", hue=\"cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = keep_fw.merge(X_val, left_on='nucleus_id', right_on='pre_nucleus_id')\n",
    "\n",
    "valid_X = X_val.select_dtypes(include='number').drop([\"ID\",\"pre_nucleus_id\", \"post_nucleus_id\"], axis = 1)\n",
    "\n",
    "valid_y = y_val\n",
    "\n",
    "train_X = X_train.select_dtypes(include='number').drop([\"ID\", \"pre_nucleus_id\", \"post_nucleus_id\"], axis = 1)\n",
    "train_y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 118903 entries, 0 to 118902\n",
      "Data columns (total 22 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   nucleus_id                      118903 non-null  int64  \n",
      " 1   feature_weight_330              118903 non-null  float64\n",
      " 2   feature_weight_328              118903 non-null  float64\n",
      " 3   adp_dist                        118903 non-null  float64\n",
      " 4   post_skeletal_distance_to_soma  118903 non-null  float64\n",
      " 5   pre_skeletal_distance_to_soma   118903 non-null  float64\n",
      " 6   pre_oracle                      118903 non-null  float64\n",
      " 7   pre_test_score                  118903 non-null  float64\n",
      " 8   post_oracle                     118903 non-null  float64\n",
      " 9   post_test_score                 118903 non-null  float64\n",
      " 10  post_nucleus_x                  118903 non-null  float64\n",
      " 11  post_nucleus_y                  118903 non-null  float64\n",
      " 12  post_nucleus_z                  118903 non-null  float64\n",
      " 13  me_similarity                   118903 non-null  float64\n",
      " 14  fw_similarity                   118903 non-null  float64\n",
      " 15  nuclei_adp_dist                 118903 non-null  float64\n",
      " 16  area1                           118903 non-null  int64  \n",
      " 17  area2                           118903 non-null  int64  \n",
      " 18  area3                           118903 non-null  int64  \n",
      " 19  AL_pre                          118903 non-null  int64  \n",
      " 20  RL_pre                          118903 non-null  int64  \n",
      " 21  V1_pre                          118903 non-null  int64  \n",
      "dtypes: float64(15), int64(7)\n",
      "memory usage: 20.0 MB\n"
     ]
    }
   ],
   "source": [
    "train_X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network (I am giving up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample the data\n",
    "ros = RandomOverSampler(random_state=0, sampling_strategy = 'minority')\n",
    "X_trainr, y_trainr = ros.fit_resample(\n",
    "        train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnet_single(act_fun, p, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Function that constructs a single hidden layer neural network with p neurons using different activation functions\n",
    "\n",
    "    Inputs:\n",
    "        - act_fun: a string giving the name of the activation function to be used\n",
    "        - p: the number of neurons in the neural network\n",
    "        - X_train, y_train: training data\n",
    "        - X_val, y_val: validation data\n",
    "    \n",
    "    Outputs:\n",
    "        - model: the neural network model\n",
    "        - train_time: the time needed to train the model\n",
    "    \"\"\"\n",
    "    keras.utils.set_random_seed(12)\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(p, activation=act_fun), # hidden layer\n",
    "        tf.keras.layers.Dense(10, activation='softmax') # output class probabilities\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.005),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    st = time.time() # start timer\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0) # fit the model to training data\n",
    "\n",
    "    et = time.time() # end timer\n",
    "\n",
    "    train_time = et-st # training time\n",
    "\n",
    "    accuracy_res = round(model.evaluate(X_val, y_val, verbose=0)[1],3) # get the accuracy result\n",
    "    \n",
    "    print(model.metrics_names[1], \"for\", act_fun, \"with p =\", str(p), \":\", str(accuracy_res)) # print the accuracy result\n",
    "\n",
    "    return model, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2042, in test_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2025, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2013, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1893, in test_step\n        y_pred = self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"dense_2\" is incompatible with the layer: expected axis -1 of input shape to have value 19, but received input with shape (None, 22)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 22), dtype=float64)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/gracewang/Documents/GitHub/elecfinal/Grace/Testing_ml_pipeline_Grace.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gracewang/Documents/GitHub/elecfinal/Grace/Testing_ml_pipeline_Grace.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model, train_time \u001b[39m=\u001b[39m nnet_single(\u001b[39m\"\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m10\u001b[39;49m, X_trainr, y_trainr, valid_X, valid_y)\n",
      "\u001b[1;32m/Users/gracewang/Documents/GitHub/elecfinal/Grace/Testing_ml_pipeline_Grace.ipynb Cell 25\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gracewang/Documents/GitHub/elecfinal/Grace/Testing_ml_pipeline_Grace.ipynb#X54sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m et \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m# end timer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gracewang/Documents/GitHub/elecfinal/Grace/Testing_ml_pipeline_Grace.ipynb#X54sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m train_time \u001b[39m=\u001b[39m et\u001b[39m-\u001b[39mst \u001b[39m# training time\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gracewang/Documents/GitHub/elecfinal/Grace/Testing_ml_pipeline_Grace.ipynb#X54sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m accuracy_res \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(model\u001b[39m.\u001b[39;49mevaluate(X_val, y_val, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)[\u001b[39m1\u001b[39m],\u001b[39m3\u001b[39m) \u001b[39m# get the accuracy result\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gracewang/Documents/GitHub/elecfinal/Grace/Testing_ml_pipeline_Grace.ipynb#X54sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mmetrics_names[\u001b[39m1\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mfor\u001b[39m\u001b[39m\"\u001b[39m, act_fun, \u001b[39m\"\u001b[39m\u001b[39mwith p =\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(p), \u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(accuracy_res)) \u001b[39m# print the accuracy result\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gracewang/Documents/GitHub/elecfinal/Grace/Testing_ml_pipeline_Grace.ipynb#X54sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model, train_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/b8/zl2jm8vs42b9q_gbk09_pdn40000gn/T/__autograph_generated_filec1h6fk_o.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2042, in test_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2025, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2013, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1893, in test_step\n        y_pred = self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"dense_2\" is incompatible with the layer: expected axis -1 of input shape to have value 19, but received input with shape (None, 22)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 22), dtype=float64)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "model, train_time = nnet_single(\"relu\", 10, X_trainr, y_trainr, valid_X, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation for Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Function that outputs a model with optimal hyperparameters\n",
    "    based on a validation set using grid search\n",
    "\n",
    "    Inputs:\n",
    "    model: provided model\n",
    "    param_grid: dictionary of parameters and values to validate on\n",
    "    e.g. \n",
    "    {'C': [0.001,0.01,0.1,1,10], \n",
    "    'gamma':[0.1,1,10,100], \n",
    "    'kernel':('linear', 'rbf')}\n",
    "    valid_X: validation X of data (pandas df)\n",
    "    valid_y: validation y of data\n",
    "\n",
    "    Outputs: \n",
    "    clf: provided model with optimum hyperparameters\n",
    "    \"\"\"\n",
    "pre_valid_models = [LinearDiscriminantAnalysis()]\n",
    "param_grids = [\n",
    "    {\n",
    "    'solver' : ['lsqr', 'eigen', 'svd'],\n",
    "    'shrinkage' : ['auto']\n",
    "    }]\n",
    "post_valid_models = []\n",
    "\n",
    "for i in range(len(pre_valid_models)):\n",
    "    best_clf = validation(model = pre_valid_models[i], \n",
    "                                        param_grid = param_grids[i], \n",
    "                                        valid_X = train_X, \n",
    "                                        valid_y = train_y)\n",
    "    post_valid_models.append(best_clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Alternative validation) USING ALL SVDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_valid_models = [SVC()]\n",
    "param_grids = [\n",
    "    {\n",
    "    'kernel':['rbf'],\n",
    "    'C': [0.1, 1],\n",
    "    }]\n",
    "post_valid_models = []\n",
    "\n",
    "for i in range(len(pre_valid_models)):\n",
    "    best_clf = validation(model = pre_valid_models[i], \n",
    "                                        param_grid = param_grids[i], \n",
    "                                        valid_X = valid_X, \n",
    "                                        valid_y = valid_y)\n",
    "    post_valid_models.append(best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covariance_estimator': None,\n",
       " 'n_components': None,\n",
       " 'priors': None,\n",
       " 'shrinkage': 'auto',\n",
       " 'solver': 'lsqr',\n",
       " 'store_covariance': False,\n",
       " 'tol': 0.0001}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_valid_models[0].get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_X = X_query.select_dtypes(include='number').drop([\"ID\", \"pre_nucleus_id\", \"post_nucleus_id\"], axis = 1)\n",
    "query_y = y_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Function that takes in a dataframe of data and outputs \n",
    "    a fitted \"optimal\" model\n",
    "\n",
    "    Inputs:\n",
    "    - train: training set\n",
    "    - query: query set\n",
    "    - models: dictionary of (model_name : model function) to train and predict on, with optimized \n",
    "    parameters already.\n",
    "\n",
    "    Outputs:\n",
    "    - best_clf: The optimum classifier function fitted over training data\n",
    "\n",
    "    - accuracy_score: list of accuracies based on order of models\n",
    "    passed.\n",
    "    \"\"\"\n",
    "##Change this according to the models you passed for validation\n",
    "models = {\"LDA\": post_valid_models[0]}\n",
    "accuracy_score, best_clf, trained_models = train_n_predict(train_X, train_y, query_X, query_y, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models[\"LDA\"].save_weights('top_submission_rfc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracies are {'LDA': 0.7471878711660729}\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracies are\", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nucleus_id', 'feature_weight_330', 'feature_weight_328', 'ID',\n",
       "       'adp_dist', 'post_skeletal_distance_to_soma',\n",
       "       'pre_skeletal_distance_to_soma', 'pre_oracle', 'pre_test_score',\n",
       "       'post_oracle', 'post_test_score', 'compartment', 'pre_brain_area',\n",
       "       'post_brain_area', 'post_nucleus_x', 'post_nucleus_y', 'post_nucleus_z',\n",
       "       'pre_nucleus_id', 'post_nucleus_id', 'pre_feature_weights',\n",
       "       'post_feature_weights', 'pre_morph_embeddings', 'post_morph_embeddings',\n",
       "       'me_similarity', 'fw_similarity', 'projection_group', 'axonal_coords',\n",
       "       'dendritic_coords', 'pre_rf_coords', 'post_rf_coords',\n",
       "       'pre_nucleus_coords', 'nuclei_adp_dist', 'area1', 'area2', 'area3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard_path = \"../Data/leaderboard_data.csv\"\n",
    "sub_data = cleaner(leaderboard_path, feature_path, morph_path, submission = True)\n",
    "sub_data = area_cols(sub_data)\n",
    "sub_data = keep_fw.merge(sub_data, left_on='nucleus_id', right_on='pre_nucleus_id')\n",
    "\n",
    "sub_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nucleus_id', 'feature_weight_330', 'feature_weight_328', 'ID',\n",
       "       'adp_dist', 'post_skeletal_distance_to_soma',\n",
       "       'pre_skeletal_distance_to_soma', 'pre_oracle', 'pre_test_score',\n",
       "       'post_oracle', 'post_test_score', 'post_nucleus_x', 'post_nucleus_y',\n",
       "       'post_nucleus_z', 'me_similarity', 'fw_similarity', 'nuclei_adp_dist',\n",
       "       'area1', 'area2', 'area3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_data = sub_data.select_dtypes(include='number').drop([\"pre_nucleus_id\", \"post_nucleus_id\"], axis = 1)\n",
    "lb_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a boolean prediction solution\n",
    "lb_data[\"connected\"] = trained_models[\"LDA\"].predict(lb_data.drop(\"ID\", axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = lb_data.filter(['ID','connected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data.to_csv('submission_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
