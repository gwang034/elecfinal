{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\86185\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'D:\\Fall23 Coursework\\ELEC478\\Competition\\elecfinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data.data_cleaner import cleaner\n",
    "from Didi.ml_pipeline_final import validation, query\n",
    "from ml_pipeline import clean_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean data\n",
    "train_path = \"../Data/train_data.csv\"\n",
    "feature_path = \"../Data/feature_weights.csv\"\n",
    "morph_path = \"../Data/imputed_morph_embed.csv\"\n",
    "X_train, X_val, X_query, y_train, y_val, y_query = clean_split(train_path, feature_path, morph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample X_train_feat\n",
    "ros = RandomOverSampler(random_state=0, sampling_strategy = 'minority')\n",
    "X_train, y_train = ros.fit_resample(\n",
    "        X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(column, df, suffix=''):\n",
    "    \"\"\"\n",
    "    one-hot encodes this shit\n",
    "    \"\"\"\n",
    "    cats = pd.unique(df[column])\n",
    "\n",
    "    for cat in cats:\n",
    "        new_col = cat+suffix\n",
    "        df[new_col] = df[column]==cat\n",
    "        df[new_col] = df[new_col].astype('int')\n",
    "    \n",
    "    df = df.drop(columns=column)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode brain areas for all\n",
    "X_train = one_hot('pre_brain_area', X_train, '_pre')\n",
    "X_train = one_hot('post_brain_area', X_train, '_post')\n",
    "\n",
    "X_val = one_hot('pre_brain_area', X_val, '_pre')\n",
    "X_val = one_hot('post_brain_area', X_val, '_post')\n",
    "\n",
    "X_query = one_hot('pre_brain_area', X_query, '_pre')\n",
    "X_query = one_hot('post_brain_area', X_query, '_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode brain areas\n",
    "area1 = [\"basal\", \"soma\"]\n",
    "area2 = [\"axon\", \"apical\", \"oblique\", \"apical_shaft\"]\n",
    "area3 = [\"apical_tuft\"]\n",
    "\n",
    "def area_cols(df):\n",
    "    df[\"area1\"] = df[\"compartment\"].isin(area1).astype('int')\n",
    "    df[\"area2\"] = df[\"compartment\"].isin(area2).astype('int')\n",
    "    df[\"area3\"] = df[\"compartment\"].isin(area3).astype('int')\n",
    "    df.drop(columns='compartment')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = area_cols(X_train)\n",
    "X_val = area_cols(X_val)\n",
    "X_query = area_cols(X_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.select_dtypes('number')\n",
    "X_val = X_val.select_dtypes('number')\n",
    "X_query = X_query.select_dtypes('number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_min = np.array(X_train)\n",
    "X_val_min = np.array(X_val)\n",
    "X_query_min = np.array(X_query)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_query = np.array(y_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198406, 38)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198406,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_min).clone().to(torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train).clone().to(torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_tensor = torch.tensor(X_val_min).clone().to(torch.float32)\n",
    "y_valid_tensor = torch.tensor(y_val).clone().to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_query_tensor = torch.tensor(X_query_min).clone().to(torch.float32)\n",
    "y_query_tensor = torch.tensor(y_query).clone().to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating neural network\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_classes, activation=nn.ReLU):\n",
    "        super(MLP, self).__init__()\n",
    "        dimensions = [input_size] + hidden_sizes + [num_classes]\n",
    "        self.linears = nn.ModuleList([nn.Linear(dimensions[i], dimensions[i+1])\n",
    "                                      for i in range(len(dimensions) - 1)])\n",
    "        self.activation = activation()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.linears[:-1]:\n",
    "            x = self.activation(layer(x))\n",
    "        out = self.linears[-1](x)\n",
    "        return out\n",
    "    \n",
    "# Functions to train and test the model\n",
    "def train_model(model, X, y, X_test, y_test, loss_fn, optimizer, num_epochs):\n",
    "    train_loss, test_loss = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(X)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Save losses\n",
    "        with torch.no_grad():\n",
    "            train_loss.append(loss.item())\n",
    "            test_loss.append(loss_fn(model(X_test), y_test).item())\n",
    "    return train_loss, test_loss\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == y).sum().item()\n",
    "        return correct / y.size(0), predicted\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10000\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198406, 38)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 38\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = dict()\n",
    "valid_losses = dict()\n",
    "accuracies = dict()\n",
    "learning_rates = np.logspace(-4,0, num = 20)\n",
    "for n in [2,3,4]:\n",
    "    for learning_rate in learning_rates:\n",
    "        model = MLP(input_size, [128]*n, num_classes)\n",
    "        model = model.to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        train_loss, valid_loss = train_model(model, X_train_tensor, y_train_tensor, \n",
    "                                                X_valid_tensor, y_valid_tensor, \n",
    "                                            loss_fn, optimizer, num_epochs)\n",
    "        __, y_hat = evaluate_model(model, X_valid_tensor, y_valid_tensor)\n",
    "        y_hat = np.array(y_hat)\n",
    "        accuracy = balanced_accuracy_score(y_val, y_hat)\n",
    "        accuracies[(n,learning_rate)] = accuracy\n",
    "        print(f\"The accuracy is {accuracy} and {n} layers and learning rate of {learning_rate}\")\n",
    "accuracies_df = pd.DataFrame([(x[0], x[1], y) for x, y in accuracies.items()], columns=['x', 'y', 'value'])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params= max(accuracies, key=accuracies.get)\n",
    "n = best_params[0]\n",
    "lr = best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params= max(accuracies, key=accuracies.get)\n",
    "n = 2\n",
    "lr = best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard_path = \"../Data/leaderboard_data.csv\"\n",
    "sub_data = cleaner(leaderboard_path, feature_path, morph_path, submission = True)\n",
    "sub_data = area_cols(sub_data)\n",
    "sub_data = one_hot('pre_brain_area', sub_data, '_pre')\n",
    "sub_data = one_hot('post_brain_area', sub_data, '_post')\n",
    "sub_data = sub_data.select_dtypes('number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = np.array(sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data_tensor = torch.tensor(sub_data).clone().to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_size, [128]*n, num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train_loss, valid_loss = train_model(model, X_train_tensor, y_train_tensor, \n",
    "                                        X_valid_tensor, y_valid_tensor, \n",
    "                                    loss_fn, optimizer, num_epochs)\n",
    "with torch.no_grad():\n",
    "    outputs = model(sub_data_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data_full = cleaner(leaderboard_path, feature_path, morph_path, submission = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data_full[\"connected\"] = np.array(predicted).astype(\"bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = sub_data_full.filter(['ID','connected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data.to_csv('submission_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
