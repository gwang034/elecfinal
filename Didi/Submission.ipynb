{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#load in training data on each potential synapse\n",
    "data = pd.read_csv(\"../Data/train_data.csv\")\n",
    "\n",
    "#load in additional features for each neuron\n",
    "feature_weights = pd.read_csv(\"../Data/feature_weights.csv\")\n",
    "morph_embeddings = pd.read_csv(\"../Data/morph_embeddings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all feature_weight_i columns into a single np.array column\n",
    "feature_weights[\"feature_weights\"] = (\n",
    "    feature_weights.filter(regex=\"feature_weight_\")\n",
    "    .sort_index(axis=1)\n",
    "    .apply(lambda x: np.array(x), axis=1)\n",
    ")\n",
    "# delete the feature_weight_i columns\n",
    "feature_weights.drop(\n",
    "    feature_weights.filter(regex=\"feature_weight_\").columns, axis=1, inplace=True\n",
    ")\n",
    "\n",
    "# join all morph_embed_i columns into a single np.array column\n",
    "morph_embeddings[\"morph_embeddings\"] = (\n",
    "    morph_embeddings.filter(regex=\"morph_emb_\")\n",
    "    .sort_index(axis=1)\n",
    "    .apply(lambda x: np.array(x), axis=1)\n",
    ")\n",
    "# delete the morph_embed_i columns\n",
    "morph_embeddings.drop(\n",
    "    morph_embeddings.filter(regex=\"morph_emb_\").columns, axis=1, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    data.merge(\n",
    "        feature_weights.rename(columns=lambda x: \"pre_\" + x), \n",
    "        how=\"left\", \n",
    "        validate=\"m:1\",\n",
    "        copy=False,\n",
    "    )\n",
    "    .merge(\n",
    "        feature_weights.rename(columns=lambda x: \"post_\" + x),\n",
    "        how=\"left\",\n",
    "        validate=\"m:1\",\n",
    "        copy=False,\n",
    "    )\n",
    "    .merge(\n",
    "        morph_embeddings.rename(columns=lambda x: \"pre_\" + x),\n",
    "        how=\"left\",\n",
    "        validate=\"m:1\",\n",
    "        copy=False,\n",
    "    )\n",
    "    .merge(\n",
    "        morph_embeddings.rename(columns=lambda x: \"post_\" + x),\n",
    "        how=\"left\",\n",
    "        validate=\"m:1\",\n",
    "        copy=False,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature weight similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine similarity function\n",
    "def row_feature_similarity(row):\n",
    "    pre = row[\"pre_feature_weights\"]\n",
    "    post = row[\"post_feature_weights\"]\n",
    "    return (pre * post).sum() / (np.linalg.norm(pre) * np.linalg.norm(post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the cosine similarity between the pre- and post- feature weights\n",
    "data[\"fw_similarity\"] = data.apply(row_feature_similarity, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### projection group direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate projection group as pre->post\n",
    "data[\"projection_group\"] = (\n",
    "    data[\"pre_brain_area\"].astype(str)\n",
    "    + \"->\"\n",
    "    + data[\"post_brain_area\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['fw_similarity'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Fall23 Coursework\\ELEC478\\Competition\\elecfinal\\Didi\\Submission.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Fall23%20Coursework/ELEC478/Competition/elecfinal/Didi/Submission.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pipe \u001b[39m=\u001b[39m Pipeline(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Fall23%20Coursework/ELEC478/Competition/elecfinal/Didi/Submission.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     [(\u001b[39m\"\u001b[39m\u001b[39mscaler\u001b[39m\u001b[39m\"\u001b[39m, StandardScaler()), (\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, LogisticRegression(random_state\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Fall23%20Coursework/ELEC478/Competition/elecfinal/Didi/Submission.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Fall23%20Coursework/ELEC478/Competition/elecfinal/Didi/Submission.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# fit model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Fall23%20Coursework/ELEC478/Competition/elecfinal/Didi/Submission.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m pipe\u001b[39m.\u001b[39mfit(train_data[[\u001b[39m\"\u001b[39;49m\u001b[39mfw_similarity\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39madp_dist\u001b[39;49m\u001b[39m\"\u001b[39;49m]], train_data[\u001b[39m\"\u001b[39m\u001b[39mconnected\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Fall23%20Coursework/ELEC478/Competition/elecfinal/Didi/Submission.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# predict on test data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Fall23%20Coursework/ELEC478/Competition/elecfinal/Didi/Submission.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m test_data[\u001b[39m\"\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pipe\u001b[39m.\u001b[39mpredict_proba(test_data[[\u001b[39m\"\u001b[39m\u001b[39mfw_similarity\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39madp_dist\u001b[39m\u001b[39m\"\u001b[39m]])[:, \u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3902\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3900\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3901\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3902\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3904\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3905\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6116\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6118\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6178\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6177\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6178\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['fw_similarity'] not in index\""
     ]
    }
   ],
   "source": [
    "# split into a train and test set \n",
    "#(Even though we're working with the competition training set, you may want to have your own internal train and test sets.)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=1)\n",
    "\n",
    "# create pipeline\n",
    "pipe = Pipeline(\n",
    "    [(\"scaler\", StandardScaler()), (\"model\", LogisticRegression(random_state=2))]\n",
    ")\n",
    "\n",
    "# fit model\n",
    "pipe.fit(train_data[[\"fw_similarity\", \"adp_dist\"]], train_data[\"connected\"])\n",
    "\n",
    "# predict on test data\n",
    "test_data[\"pred\"] = pipe.predict_proba(test_data[[\"fw_similarity\", \"adp_dist\"]])[:, 1]\n",
    "\n",
    "# compute accuracy\n",
    "print(f\"accuracy: {accuracy_score(test_data['connected'], test_data['pred'] > .5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_data['connected'], test_data['pred'] > .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"balanced accuracy: {balanced_accuracy_score(test_data['connected'], test_data['pred'] > .5)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# oversample connected neuron pairs\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(\n",
    "    train_data[[\"fw_similarity\", \"adp_dist\"]], train_data[\"connected\"]\n",
    ")\n",
    "\n",
    "# fit model\n",
    "pipe.fit(X_resampled, y_resampled)\n",
    "\n",
    "# predict on test data\n",
    "test_data[\"pred\"] = pipe.predict_proba(test_data[[\"fw_similarity\", \"adp_dist\"]])[:, 1]\n",
    "\n",
    "# compute accuracy\n",
    "print(f\"accuracy: {accuracy_score(test_data['connected'], test_data['pred'] > .5)}\")\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(test_data['connected'], test_data['pred'] > .5))\n",
    "\n",
    "# compute balanced accuracy\n",
    "print(\n",
    "    f\"balanced accuracy: {balanced_accuracy_score(test_data['connected'], test_data['pred'] > .5)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to first load and merge the leaderboard data to have the same format as the training set\n",
    "lb_data = pd.read_csv(\"./leaderboard_data.csv\")\n",
    "lb_data = (\n",
    "    lb_data.merge(\n",
    "        feature_weights.rename(columns=lambda x: \"pre_\" + x), \n",
    "        how=\"left\", \n",
    "        validate=\"m:1\",\n",
    "        copy=False,\n",
    "    )\n",
    "    .merge(\n",
    "        feature_weights.rename(columns=lambda x: \"post_\" + x),\n",
    "        how=\"left\",\n",
    "        validate=\"m:1\",\n",
    "        copy=False,\n",
    "    )\n",
    "    .merge(\n",
    "        morph_embeddings.rename(columns=lambda x: \"pre_\" + x),\n",
    "        how=\"left\",\n",
    "        validate=\"m:1\",\n",
    "        copy=False,\n",
    "    )\n",
    "    .merge(\n",
    "        morph_embeddings.rename(columns=lambda x: \"post_\" + x),\n",
    "        how=\"left\",\n",
    "        validate=\"m:1\",\n",
    "        copy=False,\n",
    "    )\n",
    ")\n",
    "# compute the cosine similarity between the pre- and post- feature weights\n",
    "lb_data[\"fw_similarity\"] = lb_data.apply(row_feature_similarity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample connected neuron pairs for full training data\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(\n",
    "    data[[\"fw_similarity\", \"adp_dist\"]], data[\"connected\"]\n",
    ")\n",
    "\n",
    "# fit model\n",
    "pipe.fit(X_resampled, y_resampled)\n",
    "\n",
    "# predict on leaderboard data\n",
    "lb_data[\"pred\"] = pipe.predict_proba(lb_data[[\"fw_similarity\", \"adp_dist\"]])[:, 1]\n",
    "\n",
    "#create a boolean prediction solution\n",
    "lb_data[\"connected\"] = lb_data[\"pred\"] > .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns should be ID, connected\n",
    "submission_data = lb_data.filter(['ID','connected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing csv files\n",
    "submission_data.to_csv('example_submission_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
